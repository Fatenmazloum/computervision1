{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Colab allows you to run code in a cloud environment, and one of its main benefits is that it provides access to GPUs (and even TPUs) for free (though there are limitations on usage). This can significantly speed up the execution of certain tasks, especially for machine learning models or data processing tasks that require heavy computation. Already have python and it run jupyter notebook.\n",
    "\n",
    "Python installed, along with a lot of commonly used libraries such as TensorFlow, PyTorch, NumPy, Pandas, and many others. If you want to download extra librarier just type !pip install scikit-learn\n",
    "\n",
    "Colab runs in a cloud environment, meaning it doesn't have direct access to your local machine's hardware, including the webcam or display windows.\n",
    "\n",
    "cloud is just a way of storing and using data and programs over the internet instead of on your own computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1032.8ms\n",
      "Speed: 18.3ms preprocess, 1032.8ms inference, 16.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Initial center set at: 384\n",
      "\n",
      "0: 480x640 1 person, 1 potted plant, 683.9ms\n",
      "Speed: 7.8ms preprocess, 683.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 potted plant, 613.9ms\n",
      "Speed: 12.0ms preprocess, 613.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 659.8ms\n",
      "Speed: 6.5ms preprocess, 659.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 782.7ms\n",
      "Speed: 4.9ms preprocess, 782.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 887.7ms\n",
      "Speed: 12.8ms preprocess, 887.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "import time\n",
    "\n",
    "sound=r\"C:\\Users\\asus\\Desktop\\Computer Vision\\lab3\\alarm.mp3\"\n",
    "camera=cv.VideoCapture(0)\n",
    "width=int(camera.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height=int(camera.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "model=YOLO('yolov5su.pt')\n",
    "initialcenterx=None\n",
    "\n",
    "\n",
    "#time.sleep(3)\n",
    "while True:\n",
    "    ret,frame=camera.read()\n",
    "    if not ret:\n",
    "        print('no frame captured')\n",
    "        break\n",
    "    if frame.shape[0]>0 and frame.shape[1]>0:\n",
    "        results=model(frame)#detiction of objects(boxes,class names,..)\n",
    "        #cv.imshow(\"frame\",frame)#it shows each frame of the video in real-time as it is captured from the camera. \n",
    "        for box in results[0].boxes:#iterate each boundary box(object / rectangle)\n",
    "            xyxy=box.xyxy[0]#each box has its own coordniates and conf and cls but .xyxy is tensor 2D so [0] for first row\n",
    "            x1,y1,x2,y2=map(int,xyxy.numpy())\n",
    "            cv.rectangle(frame,(x1,y1),(x2,y2),(255,0,0),2)#in patches.Rectangle((x1,y1),(w,h)) can be float but cv int pixels\n",
    "            conf=box.conf[0]\n",
    "            cls=int(box.cls[0])\n",
    "            name=results[0].names[cls]\n",
    "            result=f'{name}{conf:.2f}'\n",
    "            cv.putText(frame,result, (x1, y1 - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv.LINE_AA)\n",
    "            if name=='person':\n",
    "                centerx=(x1+x2)//2\n",
    "                centery=(y1+y2)//2\n",
    "                \n",
    "\n",
    "                if initialcenterx is None:\n",
    "                    initialcenterx = centerx  # Save the center of the first detected person\n",
    "                    print(f\"Initial center set at: {initialcenterx}\")\n",
    "\n",
    "                if initialcenterx is not None:\n",
    "                    ## Compare the current center with the initial center\n",
    "                    if centerx<initialcenterx-10:\n",
    "                        direction='left'\n",
    "                        cv.putText(frame, \"Hello Left\", (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv.LINE_AA)\n",
    "                        #playsound(sound)\n",
    "\n",
    "                    elif centerx>initialcenterx+10:\n",
    "                        direction='right'\n",
    "                        cv.putText(frame, \"Hello Right\", (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0,255), 2, cv.LINE_AA)\n",
    "                        #playsound(sound)\n",
    "                    else:\n",
    "                        direction='center'\n",
    "                        cv.putText(frame, \"Hello Center\", (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0 , 255), 2, cv.LINE_AA)\n",
    "                    \n",
    "        \n",
    "        cv.imshow(\"frame\",frame)  \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    else:\n",
    "        print('no frame dimession')\n",
    "        break\n",
    "    if cv.waitKey(2) & 0xFF==ord('q'):#wait 2 ms before moving to other frame\n",
    "        break\n",
    "camera.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
