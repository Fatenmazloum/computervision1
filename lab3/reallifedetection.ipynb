{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 tv, 743.0ms\n",
      "Speed: 9.8ms preprocess, 743.0ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 823.3ms\n",
      "Speed: 19.3ms preprocess, 823.3ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 838.1ms\n",
      "Speed: 6.0ms preprocess, 838.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 1 tv, 775.3ms\n",
      "Speed: 16.8ms preprocess, 775.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 1 tv, 623.5ms\n",
      "Speed: 5.8ms preprocess, 623.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 1 tv, 626.4ms\n",
      "Speed: 6.1ms preprocess, 626.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 821.4ms\n",
      "Speed: 8.0ms preprocess, 821.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 740.3ms\n",
      "Speed: 8.5ms preprocess, 740.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 potted plant, 737.7ms\n",
      "Speed: 6.0ms preprocess, 737.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 couch, 1 tv, 714.2ms\n",
      "Speed: 6.4ms preprocess, 714.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 potted plant, 2 vases, 639.9ms\n",
      "Speed: 5.8ms preprocess, 639.9ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 couch, 1 potted plant, 1 tv, 1 vase, 639.8ms\n",
      "Speed: 7.6ms preprocess, 639.8ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 couch, 2 potted plants, 1 tv, 1 vase, 610.8ms\n",
      "Speed: 6.0ms preprocess, 610.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 chair, 1 couch, 1 potted plant, 1 tv, 1 vase, 616.1ms\n",
      "Speed: 7.6ms preprocess, 616.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 bowls, 1 chair, 1 couch, 1 potted plant, 1 tv, 1 vase, 600.0ms\n",
      "Speed: 6.1ms preprocess, 600.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 1 vase, 663.7ms\n",
      "Speed: 5.4ms preprocess, 663.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 604.6ms\n",
      "Speed: 8.3ms preprocess, 604.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 vase, 620.5ms\n",
      "Speed: 6.9ms preprocess, 620.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 bowls, 1 couch, 1 book, 1 vase, 602.2ms\n",
      "Speed: 9.2ms preprocess, 602.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 1 vase, 603.5ms\n",
      "Speed: 6.9ms preprocess, 603.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 1 vase, 620.6ms\n",
      "Speed: 6.2ms preprocess, 620.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 1 vase, 615.7ms\n",
      "Speed: 5.0ms preprocess, 615.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 1 vase, 616.4ms\n",
      "Speed: 6.2ms preprocess, 616.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 1 vase, 610.0ms\n",
      "Speed: 7.8ms preprocess, 610.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 book, 1 vase, 609.0ms\n",
      "Speed: 10.9ms preprocess, 609.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 chair, 1 couch, 1 vase, 605.1ms\n",
      "Speed: 6.5ms preprocess, 605.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 vase, 614.2ms\n",
      "Speed: 7.7ms preprocess, 614.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 vase, 603.7ms\n",
      "Speed: 6.0ms preprocess, 603.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 vase, 599.4ms\n",
      "Speed: 6.1ms preprocess, 599.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bowl, 1 couch, 1 vase, 792.1ms\n",
      "Speed: 6.0ms preprocess, 792.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 601.8ms\n",
      "Speed: 9.7ms preprocess, 601.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 627.9ms\n",
      "Speed: 5.5ms preprocess, 627.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 623.5ms\n",
      "Speed: 5.6ms preprocess, 623.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 602.2ms\n",
      "Speed: 6.5ms preprocess, 602.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "\n",
    "model=YOLO('yolov5s.pt')\n",
    "\n",
    "# Open the camera (0 usually means the default webcam)\n",
    "camera = cv.VideoCapture(0)\n",
    "\n",
    "# Get the camera's width and height\n",
    "width = int(camera.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(camera.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "path=r\"C:\\Users\\asus\\Desktop\\Computer Vision\\lab3\\alarm.mp3\"\n",
    "\n",
    "# Let the camera warm up\n",
    "#time.sleep(1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()  # Read a frame from the camera\n",
    "    #ret: This is a boolean value that indicates whether the frame was successfully captured from the camera.\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image.\")\n",
    "        break  # Exit the loop if the frame capture failed\n",
    "\n",
    "    # Check if the frame has valid width and height\n",
    "    if frame.shape[0] > 0 and frame.shape[1] > 0:\n",
    "        #cv.imshow(\"Camera Feed\", frame)  # Show the captured frame\n",
    "        results=model(frame)\n",
    "        for box in results[0].boxes:#each box have coord as tensor flow[number of objects dedicted,4],conf,cls\n",
    "          xyxy=box.xyxy[0]\n",
    "          x1,y1,x2,y2=map(int, xyxy.numpy())#The map() function in Python applies a given function to every item in an iterable (in this case, the NumPy array\n",
    "          cv.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue color box#should be int because cv works with integer pixels\n",
    "          cls=int(box.cls[0])\n",
    "          conf=box.conf[0]\n",
    "          name=results[0].names[cls]\n",
    "          result=f'{name}{conf:.2f}'\n",
    "          cv.putText(frame,result, (x1, y1 - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv.LINE_AA)\n",
    "          cv.imshow(\"camera feed\",frame)\n",
    "          #if name=='person':\n",
    "              #playsound(path)\n",
    "    \n",
    "#open cv(0,0,0)black ,(255,25,255)white,(255,0,0)blueBGR,(0,156,250)orange\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: Invalid frame dimensions.\")\n",
    "\n",
    "    # Wait for a key press; if 'q' is pressed, exit the loop\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):  # 1 ms delay for each frame\n",
    "        break\n",
    "    #wait for 1 ms if no key pressed move to second frame\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()#stop conncetion to camera\n",
    "cv.destroyAllWindows()#close all windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
