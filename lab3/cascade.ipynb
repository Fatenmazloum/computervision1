{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cascade: Detect specific objects (e.g., faces, cars)\n",
    "\n",
    "Contour Detection is best when you need to segment and detect the shape of an object in an image.\n",
    "\n",
    "Cascade Classifiers are more suited for specific object detection tasks like face or pedestrian detection, especially when working with pre-trained models.\n",
    "\n",
    "Edge Detection is useful when you need to identify outlines but don't necessarily need to detect the full object.\n",
    "\n",
    "Corner Detection is helpful when you're looking for distinctive points to track or match features between different images.\n",
    "\n",
    "Best scalar factor for face btw 1.1 and 1.5\n",
    "for eyes 1.1 (zoom in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.CascadeClassifier: This function is used to load a pre-trained Haar Cascade classifier, which detects specific objects (in this case, faces and eyes) based on the features it has learned during training.\n",
    "\n",
    "cv2.data.haarcascades: This is a path to the directory where OpenCV stores pre-trained Haar Cascade XML files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 56 143 272 272]\n",
      "2\n",
      "[[203 212  63  63]\n",
      " [108 222  58  58]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "# Load the pre-trained classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "img=cv2.imread(r\"c:\\Users\\asus\\Downloads\\TheAIEngineers-Notebooks-master\\ComputerVisionNotebooks\\DATA\\Nadia_Murad.jpg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=face_cascade.detectMultiScale(gray,1.3)\n",
    "#1.5 is the scale factor that determines how much the image is resized during detection.\n",
    "#5 is the minimum number of neighbors that a detected region must have to be considered a valid face.\n",
    "#faces is a list of rectangles where each rectangle corresponds to a detected face.\n",
    "#Each rectangle is described by 4 values: (x, y, w, h) — top-left corner coordinates, width, and height of the face.\n",
    "print(len(faces))\n",
    "print(faces[0])\n",
    "eye=eye_cascade.detectMultiScale(gray,1.2)\n",
    "print(len(eye))\n",
    "print(eye)\n",
    "   \n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,[x,y],[w+x,h+y],[255,0,0],2)\n",
    "    \n",
    "for(i,j,z,l) in eye:\n",
    "     cv2.rectangle(img,(i,j),(i+z,l+j),[0,255,0],2)\n",
    "cv2.imshow('faces',img)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[129  68  24  24]\n",
      " [ 90  69  26  26]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "# Load the pre-trained classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "img=cv2.imread(r\"C:\\Users\\asus\\Desktop\\Computer Vision\\lab3\\face.PNG\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "eyes=eye_cascade.detectMultiScale(gray,1.1,5)\n",
    "#If scaleFactor = 1.1, it means the image is reduced by 10% at each level\n",
    "#faces is a array list of rectangles where each rectangle corresponds to a detected face.\n",
    "#Each rectangle is described by 4 values: (x, y, w, h) — top-left corner coordinates, width, and height of the face.\n",
    "print(len(eyes))\n",
    "print(eyes)\n",
    "for(x,y,w,h) in eyes:\n",
    "    cv2.rectangle(img,[x,y],[w+x,h+y],[255,0,0],2)\n",
    "cv2.imshow('eyes',img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two faces: test how scalar factor effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[283  50  66  66]\n",
      " [191  72  66  66]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "facecascade=cv.CascadeClassifier(cv.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "eyecascade=cv.CascadeClassifier(cv.data.haarcascades+'haarcascade_eye.xml')\n",
    "image=cv.imread(r\"C:\\Users\\asus\\Desktop\\Computer Vision\\lab3\\jj.jpg\")\n",
    "\n",
    "gray=cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "face=facecascade.detectMultiScale(gray,1.4,5)\n",
    "print(len(face))\n",
    "print(face)\n",
    "\n",
    "for(x,y,w,h) in face:\n",
    "    cv.rectangle(image,[x,y],[x+w,y+h],[255,0,0],2)\n",
    "\n",
    "cv.imshow(\"final\",image)\n",
    "cv.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 56 142 273 273]\n",
      "[2 4 6 7]\n"
     ]
    }
   ],
   "source": [
    "array=np.array([[ 56 ,142, 273 ,273],[2,4,6,7]])\n",
    "for i in array:\n",
    "    print (i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "142\n",
      "273\n",
      "273\n"
     ]
    }
   ],
   "source": [
    "array=np.array([ 56 ,142, 273 ,273])\n",
    "for i in array:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "142\n",
      "273\n",
      "273\n",
      "2\n",
      "4\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "array=np.array([[ 56 ,142, 273 ,273],[2,4,6,7]])\n",
    "for i in array:\n",
    "    for j in i:\n",
    "      print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 56 142 273 273]\n",
      "1 [2 4 6 7]\n"
     ]
    }
   ],
   "source": [
    "array=np.array([[ 56 ,142, 273 ,273],[2,4,6,7]])\n",
    "for i,j in enumerate(array):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 142 273 273\n",
      "2 4 6 7\n"
     ]
    }
   ],
   "source": [
    "array=np.array([[ 56 ,142, 273 ,273],[2,4,6,7]])\n",
    "for (x,y,b,m)in (array):\n",
    "    print(x,y,b,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "array=np.array([[ 56 ,142, 273 ,273],[2,4,6,7]])\n",
    "for i in range (len(array)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.int64(56), np.int64(1))\n",
      "(np.int64(142), np.int64(2))\n",
      "(np.int64(273), np.int64(3))\n",
      "(np.int64(273), np.int64(4))\n"
     ]
    }
   ],
   "source": [
    "array=np.array([ 56 ,142, 273 ,273])\n",
    "array2=np.array([ 1,2,3,4])\n",
    "for i in zip(array,array2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 1\n",
      "142 2\n",
      "273 3\n",
      "273 4\n"
     ]
    }
   ],
   "source": [
    "array=np.array([ 56 ,142, 273 ,273])\n",
    "array2=np.array([ 1,2,3,4])\n",
    "for i, j in zip(array,array2):\n",
    "    print(i,j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
